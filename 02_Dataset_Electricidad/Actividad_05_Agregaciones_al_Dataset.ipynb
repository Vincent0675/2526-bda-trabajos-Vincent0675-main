{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d13f55f9",
   "metadata": {},
   "source": [
    "# Actividad 5: Agregaciones a Dataset\n",
    "\n",
    "**Asignatura:** Big Data Aplicado.\n",
    "**Estudiante:** Byron V. Blatch Rodr√≠guez.\n",
    "**Fecha:** 26/11/2025\n",
    "\n",
    "## Objetivos de la actividad\n",
    "1. Generar agregaciones intuyendo qu√© informaci√≥n podemos adelantar o puede ser frecuentemente consultada, optimiz√°ndola.\n",
    "2. Utilizar herramientas de base de datos como MongoDB y de virtualizaci√≥n como Docker.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a355ad",
   "metadata": {},
   "source": [
    "En esta ocasi√≥n simular√© la subida de mis CSV en una base de datos, MongoDB ser√° la herramienta que utilizar√©. No har√© una instalaci√≥n nativa de mongo, sino que utilizar√© la herramienta Docker para ejecutar MongoDB virtualizadamente en mi equipo, permiti√©ndome hacer la simulaci√≥n.\n",
    "\n",
    "Para ello, en mi Pop OS! 22.04 he instalado Docker, y he descargado la imagen con el comando `docker run -d --name mi-mongo-local -p 27777:27017 mongo:latest`. Me aseguro qu ese est√© ejecutando con `docker ps` y finalmente procedo a codificar la subida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04958b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conexi√≥n establecida correctamente\n"
     ]
    }
   ],
   "source": [
    "# Importo las librer√≠a para la actividad\n",
    "from pymongo import MongoClient # Librer√≠a para conectar con MongoDB\n",
    "import pandas as pd           # Librer√≠a para manejo de dataframes\n",
    "import numpy as np            # Librer√≠a para manejo de arrays y operaciones matem√°ticas\n",
    "import matplotlib.pyplot as plt # Librer√≠a para graficar\n",
    "\n",
    "\n",
    "# Conexi√≥n a mi Mongo de Docker\n",
    "client = MongoClient(\"mongodb://localhost:27777\") # Puerto mapeado en docker run [web:80] [web:62]\n",
    "\n",
    "db = client[\"bigdata\"]        # Nombre de la database\n",
    "clientes_col = db[\"clientes\"] # Colecci√≥n de clientes\n",
    "consumos_col = db[\"consumos\"] # Colecci√≥n consumos\n",
    "\n",
    "print(\"Conexi√≥n establecida correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4932592f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              client_id                      nombre  \\\n",
      "0  99dfec6b-5bcc-453f-a0b9-aa1407614605      Hilda Bejarano-Anglada   \n",
      "1  9f5d6a32-f462-462b-a2ff-5e313b1ff8a6  Baudelio Ferr√°ndez Naranjo   \n",
      "2  805d9c84-7359-46ca-a59c-1c708b96d6f5  Juan Bautista M√°rmol Arnau   \n",
      "3  9ca72c79-f619-4ccd-9c8e-f7d2935aef2c             Eutimio Company   \n",
      "4  a3cb15e4-fb47-4f47-8489-68539e88cd51            Ale Calleja Ur√≠a   \n",
      "\n",
      "                                           direccion      ciudad  \\\n",
      "0       Calle de Marcial Molins 78, La Coru√±a, 05578   Tarragona   \n",
      "1  Avenida de Lisandro Gonz√°lez 6 Puerta 3 , Sori...      Ciudad   \n",
      "2              Rambla Lino Calleja 40, Teruel, 17484      Ciudad   \n",
      "3       Pasaje de Duilio Vila 376, Valladolid, 32478  Pontevedra   \n",
      "4  Paseo de Mar√≠a Fernanda Ca√±ellas 6 Apt. 75 , T...      Ciudad   \n",
      "\n",
      "                        email  \n",
      "0          freina@example.com  \n",
      "1  escalonasabina@example.org  \n",
      "2        nhurtado@example.org  \n",
      "3         luisa29@example.org  \n",
      "4   gomilaernesto@example.com  \n",
      "            timestamp                             client_id  consumo_kwh  \\\n",
      "0 2025-01-01 00:00:00  99dfec6b-5bcc-453f-a0b9-aa1407614605         9.85   \n",
      "1 2025-01-01 01:00:00  99dfec6b-5bcc-453f-a0b9-aa1407614605        15.27   \n",
      "2 2025-01-01 02:00:00  99dfec6b-5bcc-453f-a0b9-aa1407614605         7.23   \n",
      "3 2025-01-01 03:00:00  99dfec6b-5bcc-453f-a0b9-aa1407614605        16.62   \n",
      "4 2025-01-01 04:00:00  99dfec6b-5bcc-453f-a0b9-aa1407614605        12.45   \n",
      "\n",
      "   generado_kwh  \n",
      "0          0.73  \n",
      "1          8.30  \n",
      "2          0.93  \n",
      "3          2.80  \n",
      "4          0.52  \n"
     ]
    }
   ],
   "source": [
    "# Ahora cargamos nuestros CSV a la base de datos\n",
    "\n",
    "df_prop = pd.read_csv(\"data/propietarios.csv\")\n",
    "df_cons = pd.read_csv(\"data/consumos_generacion.csv\")\n",
    "\n",
    "# Convertir la columna 'timestamp' a datetime antes de la inserci√≥n\n",
    "df_cons['timestamp'] = pd.to_datetime(df_cons['timestamp'])\n",
    "\n",
    "print(df_prop.head())\n",
    "print(df_cons.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7de48ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insertados 500 propietarios en 'clientes'.\n",
      "Insertados 4380000 registros en 'consumos'.\n"
     ]
    }
   ],
   "source": [
    "# Limpiar colecciones por si ya ten√≠an datos de pruebas\n",
    "clientes_col.delete_many({})\n",
    "consumos_col.delete_many({})\n",
    "\n",
    "# 2) Insertar propietarios\n",
    "docs_prop = df_prop.to_dict(\"records\")\n",
    "clientes_col.insert_many(docs_prop)\n",
    "print(f\"Insertados {len(docs_prop)} propietarios en 'clientes'.\")\n",
    "\n",
    "# 3) Insertar consumos (tomar√° tiempo ya que son millones)\n",
    "docs_cons = df_cons.to_dict(\"records\")\n",
    "consumos_col.insert_many(docs_cons)\n",
    "print(f\"Insertados {len(docs_cons)} registros en 'consumos'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495d425b",
   "metadata": {},
   "source": [
    "Mis datos ya se encuentran subidos a MongoDB ejecutado virtualmente en local gracias a Docker. Lo siguiente que har√© es observar gr√°ficos de mis datos sint√©ticos antes de establecer cu√°les podr√≠an ser los patrones que me ayudar√°n a detectar \"sospechosos\" en la red el√©ctrica. Planteamos un pipeline exploratorio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4d4d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejecutando agregaci√≥n...\n",
      "‚úì Total de d√≠as completos: 182500\n",
      "Ejecutando agregaci√≥n sobre millones de registros...\n",
      "(Esto puede tardar 10-30 segundos)\n",
      "\n",
      "‚úì Agregaci√≥n completada\n",
      "Total de d√≠as completos analizados: 182500\n"
     ]
    }
   ],
   "source": [
    "# Por comodidad trabajaremos con agregaciones en MongoDB para analizar los datos.\n",
    "\n",
    "# Creamos pipelines sin filtros de umbrales para observarlo todo.\n",
    "\"\"\"\n",
    "pipeline_exploratorio = [\n",
    "    # Paso 1: Extraer d√≠a desde timestamp\n",
    "    {\n",
    "        \"$project\": {\n",
    "            \"client_id\": 1,\n",
    "            \"consumption_kwh\": 1,\n",
    "            \"day\": {\n",
    "                \"$dateToString\": {\n",
    "                    \"format\": \"%Y-%m-%d\",\n",
    "                    \"date\": \"$timestamp\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    # Paso 2: Agrupar por cliente y d√≠a\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": {\n",
    "                \"client_id\": \"$client_id\",\n",
    "                \"day\": \"$day\"\n",
    "            },\n",
    "            \"avg_consumption\": {\"$avg\": \"$consumption_kwh\"},\n",
    "            \"std_consumption\": {\"$stdDevSamp\": \"$consumption_kwh\"},\n",
    "            \"count_hours\": {\"$sum\": 1}\n",
    "        }\n",
    "    },\n",
    "    # Paso 3: Solo d√≠as completos (24 horas)\n",
    "    {\n",
    "        \"$match\": {\n",
    "            \"count_hours\": 24\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "pipeline_exploratorio = [\n",
    "    {\n",
    "        \"$project\": {\n",
    "            \"client_id\": 1,\n",
    "            \"consumo_kwh\": 1,\n",
    "            \"day\": {\n",
    "                \"$dateToString\": {\n",
    "                    \"format\": \"%Y-%m-%d\",\n",
    "                    \"date\": \"$timestamp\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": {\n",
    "                \"client_id\": \"$client_id\",\n",
    "                \"day\": \"$day\"\n",
    "            },\n",
    "            \"avg_consumption\": {\"$avg\": \"$consumo_kwh\"},\n",
    "            \"std_consumption\": {\"$stdDevSamp\": \"$consumo_kwh\"},\n",
    "            \"count_hours\": {\"$sum\": 1}\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$match\": {\n",
    "            \"count_hours\": 24\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"Ejecutando agregaci√≥n...\")\n",
    "todos_los_dias = list(consumos_col.aggregate(pipeline_exploratorio))\n",
    "print(f\"‚úì Total de d√≠as completos: {len(todos_los_dias)}\")\n",
    "\n",
    "print(\"Ejecutando agregaci√≥n sobre millones de registros...\")\n",
    "print(\"(Esto puede tardar 10-30 segundos)\")\n",
    "\n",
    "todos_los_dias = list(consumos_col.aggregate(pipeline_exploratorio))\n",
    "\n",
    "print(f\"\\n‚úì Agregaci√≥n completada\")\n",
    "print(f\"Total de d√≠as completos analizados: {len(todos_los_dias)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "154fa277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Datos convertidos a Dataframe\n",
      "\n",
      "Primeras 5 filas:\n",
      "                              client_id         day  avg_consumption  \\\n",
      "0  f0f46bf8-3dfc-4ad9-b29a-94a51d63cccf  2025-02-05         8.556667   \n",
      "1  9a7dd9eb-5304-460f-be28-aaad29c5574b  2025-05-09        10.331667   \n",
      "2  ba73fdd6-6c93-4731-b5e3-e7f5a3bc7cd1  2025-10-28         9.283750   \n",
      "3  e1e79bae-1980-489b-9634-f4bda06625ee  2025-05-09        11.532500   \n",
      "4  43a32471-f82d-454e-b991-efa01699443a  2025-06-27        12.098333   \n",
      "\n",
      "   std_consumption  \n",
      "0         6.022116  \n",
      "1         5.631001  \n",
      "2         6.261559  \n",
      "3         5.909257  \n",
      "4         5.131773  \n",
      "Dimensiones: 182500 filas y 4 columnas\n"
     ]
    }
   ],
   "source": [
    "# Ahora extraemos los datos exploratorios para generar la gr√°fica.\n",
    "\n",
    "datos = []\n",
    "\n",
    "for doc in todos_los_dias:\n",
    "    datos.append({\n",
    "        'client_id': doc['_id']['client_id'],\n",
    "        'day': doc['_id']['day'],\n",
    "        'avg_consumption': doc['avg_consumption'],\n",
    "        'std_consumption': doc['std_consumption']\n",
    "    })\n",
    "\n",
    "df_analisis = pd.DataFrame(datos)\n",
    "\n",
    "print(\"‚úì Datos convertidos a Dataframe\")\n",
    "print(f\"\\nPrimeras 5 filas:\")\n",
    "print(df_analisis.head())\n",
    "print(f\"Dimensiones: {df_analisis.shape[0]} filas y {df_analisis.shape[1]} columnas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5c0676d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "RESUMEN ESTAD√çSTICO\n",
      "======================================================================\n",
      "       avg_consumption  std_consumption\n",
      "count    182500.000000    182500.000000\n",
      "mean         10.007187         5.744621\n",
      "std           1.177541         0.559205\n",
      "min           4.872917         3.164632\n",
      "25%           9.207500         5.375465\n",
      "50%          10.013958         5.758746\n",
      "75%          10.805833         6.130014\n",
      "max          15.170417         7.899445\n",
      "\n",
      "======================================================================\n",
      "Umbrales que usar√©\n",
      "======================================================================\n",
      "\n",
      "Top 10% de consumo medio: >= 12.72 kWh/hora\n",
      "Bottom 10% de variaci√≥n: <= 4.38 kWh\n",
      "\n",
      "üí° Usaremos estos valores como umbrales para detectar sospechosos.\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"RESUMEN ESTAD√çSTICO\")\n",
    "print(\"=\"*70)\n",
    "print(df_analisis[['avg_consumption', 'std_consumption']].describe())\n",
    "\n",
    "# Calcular percentiles clave\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Umbrales que usar√©\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Top 10% de consumo\n",
    "umbral_consumo = df_analisis['avg_consumption'].quantile(0.99)\n",
    "print(f\"\\nTop 10% de consumo medio: >= {umbral_consumo:.2f} kWh/hora\")\n",
    "\n",
    "# Bottom 10% de variaci√≥n (m√°s plano)\n",
    "umbral_std = df_analisis['std_consumption'].quantile(0.01)\n",
    "print(f\"Bottom 10% de variaci√≥n: <= {umbral_std:.2f} kWh\")\n",
    "\n",
    "print(f\"\\nüí° Usaremos estos valores como umbrales para detectar sospechosos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b0cba9",
   "metadata": {},
   "source": [
    "Podemos observar que hemos obtenido un total de 182.500 registros en cuanto a consumos diarios se refiere. Aunque tengamos los n√∫meros podemos demostrarlos de manera m√°s gr√°fica y agradable para el ojo humano y de estudio. Por tanto procederemo a graficar."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigdata_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
